{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-60712b9de575>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misdir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mproblem_unittests\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Dev\\Udacity_Deep-Learning\\Deep-Learning-Project-2\\deep-learning\\image-classification\\problem_unittests.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0munittest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmock\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMagicMock\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 23:\n",
      "Image - Min Value: 4 Max Value: 238\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 6 Name: frog\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4DCFD0AFKboAaCw/wXAtOxTlohGsgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16ca7e5ebe0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 23\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    return (x / x.max())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 1 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 1]\n",
      " ..., \n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]]\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing as pp\n",
    "one_hot_encoder = None\n",
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    global one_hot_encoder\n",
    "\n",
    "    if one_hot_encoder == None:\n",
    "        one_hot_encoder = pp.LabelBinarizer()\n",
    "        one_hot_encoder.fit(x)\n",
    "\n",
    "    return one_hot_encoder.transform(x)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, shape=(None,\n",
    "                                             image_shape[0],\n",
    "                                             image_shape[1],\n",
    "                                             image_shape[2]), name=\"x\")\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.int32, shape=(None, n_classes), name=\"y\")\n",
    "\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    return tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    dim = x_tensor.get_shape().as_list()\n",
    "    shape = list(conv_ksize + (dim[-1],) + (conv_num_outputs,))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    weights = tf.Variable(tf.truncated_normal(shape,0,0.1))\n",
    "    \n",
    "    stride = list((1,)+conv_strides+(1,))\n",
    "    \n",
    "    #conv2d(input, filter, stride, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weights,stride, padding=\"SAME\", use_cudnn_on_gpu=True)\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    #tf.nn.max_pool(value, ksize, strides, padding, data_format='NHWC', name=None)\n",
    "    ksize = list((1,) + pool_ksize + (1,))\n",
    "    strides = list((1,) + pool_strides + (1,))\n",
    "    \n",
    "    #print(conv_layer)\n",
    "    #print(ksize)\n",
    "    #print(strides)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, ksize, strides, padding=\"SAME\")\n",
    "    \n",
    "    return conv_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    \n",
    "   \n",
    "    #print(x_tensor)\n",
    "    #print(tf.contrib.layers.flatten(x_tensor))\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    #print(x_tensor, num_outputs)\n",
    "    #print(tf.contrib.layers.fully_connected(x_tensor,num_outputs))\n",
    "    return tf.contrib.layers.fully_connected(x_tensor,num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    #print(x_tensor)\n",
    "    #print(num_outputs)\n",
    "    #print(tf.contrib.layers.fully_connected(x_tensor, num_outputs))\n",
    "    return tf.contrib.layers.fully_connected(x_tensor, num_outputs)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def print_stuff(message, net):\n",
    "    print(message)\n",
    "    print(net)\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    #Prints network layer info if True\n",
    "    do_print = False\n",
    "   \n",
    "    #Convolution and Max Pool Layers\n",
    "    #conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    #net = conv2d_maxpool(x, 18, (4,4), (1,1), (8,8), (1,1))\n",
    "    net = conv2d_maxpool(x, 32, (4,4), (1,1), (4,4), (1,1))\n",
    "    #net = conv2d_maxpool(x, 18, (4,4), (1,1), (8,8), (1,1))\n",
    "\n",
    "    if do_print:\n",
    "        print_stuff(\"Maxpool:\", net)\n",
    "        \n",
    "    #Flatten Layer\n",
    "    net = flatten(net)\n",
    "    \n",
    "    if do_print:\n",
    "        print_stuff(\"Flatten:\", net)\n",
    "        \n",
    "    #Tryout a dropout :D\n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    \n",
    "    if do_print:\n",
    "        print_stuff(\"Dropout:\", net)\n",
    "        \n",
    "    #2 Fully Connected Layers\n",
    "    #fully_conn(x_tensor, num_outputs)\n",
    "    net = fully_conn(net, 140)\n",
    "    net = fully_conn(net, 40)\n",
    "    net = fully_conn(net, 320)\n",
    "\n",
    "\n",
    "    \n",
    "    if do_print:\n",
    "        print_stuff(\"Fully Connected:\", net)\n",
    "    \n",
    "    net = tf.nn.dropout(net, keep_prob)\n",
    "    \n",
    "    #Output Layer!\n",
    "    net = output(net, 10)\n",
    "    \n",
    "    if do_print:\n",
    "        print_stuff(\"Output:\", net)\n",
    "    \n",
    "    return net\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    #Run TF session!\n",
    "    session.run(optimizer, feed_dict={x:feature_batch, y:label_batch, keep_prob:keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    global valid_features, valid_labels\n",
    "    #print(valid_features, valid_labels)\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y:label_batch, keep_prob:1.0})\n",
    "    accuracy = session.run(accuracy, feed_dict={x: valid_features, y:valid_labels, keep_prob:1.0})\n",
    "    \n",
    "    print('\\nLoss = {} \\t Accuracy = {}\\n'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "keep_probability = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  \n",
      "Loss = 2.2926411628723145 \t Accuracy = 0.14939998090267181\n",
      "\n",
      "Epoch  2, CIFAR-10 Batch 1:  \n",
      "Loss = 2.2472498416900635 \t Accuracy = 0.19079998135566711\n",
      "\n",
      "Epoch  3, CIFAR-10 Batch 1:  \n",
      "Loss = 2.134305953979492 \t Accuracy = 0.2651999890804291\n",
      "\n",
      "Epoch  4, CIFAR-10 Batch 1:  \n",
      "Loss = 2.011112689971924 \t Accuracy = 0.3033999800682068\n",
      "\n",
      "Epoch  5, CIFAR-10 Batch 1:  \n",
      "Loss = 1.8091822862625122 \t Accuracy = 0.35439997911453247\n",
      "\n",
      "Epoch  6, CIFAR-10 Batch 1:  \n",
      "Loss = 1.6065475940704346 \t Accuracy = 0.3741999864578247\n",
      "\n",
      "Epoch  7, CIFAR-10 Batch 1:  \n",
      "Loss = 1.501205563545227 \t Accuracy = 0.4065999686717987\n",
      "\n",
      "Epoch  8, CIFAR-10 Batch 1:  \n",
      "Loss = 1.303351879119873 \t Accuracy = 0.46119996905326843\n",
      "\n",
      "Epoch  9, CIFAR-10 Batch 1:  \n",
      "Loss = 1.1106618642807007 \t Accuracy = 0.4979999363422394\n",
      "\n",
      "Epoch 10, CIFAR-10 Batch 1:  \n",
      "Loss = 1.0097863674163818 \t Accuracy = 0.4883999526500702\n",
      "\n",
      "Epoch 11, CIFAR-10 Batch 1:  \n",
      "Loss = 1.0061776638031006 \t Accuracy = 0.47599995136260986\n",
      "\n",
      "Epoch 12, CIFAR-10 Batch 1:  \n",
      "Loss = 0.839057445526123 \t Accuracy = 0.527999997138977\n",
      "\n",
      "Epoch 13, CIFAR-10 Batch 1:  \n",
      "Loss = 0.7234569787979126 \t Accuracy = 0.5207999348640442\n",
      "\n",
      "Epoch 14, CIFAR-10 Batch 1:  \n",
      "Loss = 0.7276188731193542 \t Accuracy = 0.5171999335289001\n",
      "\n",
      "Epoch 15, CIFAR-10 Batch 1:  \n",
      "Loss = 0.6878681182861328 \t Accuracy = 0.5191999673843384\n",
      "\n",
      "Epoch 16, CIFAR-10 Batch 1:  \n",
      "Loss = 0.6475411653518677 \t Accuracy = 0.525399923324585\n",
      "\n",
      "Epoch 17, CIFAR-10 Batch 1:  \n",
      "Loss = 0.5881487131118774 \t Accuracy = 0.5475999116897583\n",
      "\n",
      "Epoch 18, CIFAR-10 Batch 1:  \n",
      "Loss = 0.5647931694984436 \t Accuracy = 0.5343999266624451\n",
      "\n",
      "Epoch 19, CIFAR-10 Batch 1:  \n",
      "Loss = 0.5299682021141052 \t Accuracy = 0.5379999876022339\n",
      "\n",
      "Epoch 20, CIFAR-10 Batch 1:  \n",
      "Loss = 0.5257344245910645 \t Accuracy = 0.5535999536514282\n",
      "\n",
      "Epoch 21, CIFAR-10 Batch 1:  \n",
      "Loss = 0.4555252492427826 \t Accuracy = 0.5583999156951904\n",
      "\n",
      "Epoch 22, CIFAR-10 Batch 1:  \n",
      "Loss = 0.4647035300731659 \t Accuracy = 0.5621999502182007\n",
      "\n",
      "Epoch 23, CIFAR-10 Batch 1:  \n",
      "Loss = 0.4485279321670532 \t Accuracy = 0.5649999380111694\n",
      "\n",
      "Epoch 24, CIFAR-10 Batch 1:  \n",
      "Loss = 0.4164050221443176 \t Accuracy = 0.5649998784065247\n",
      "\n",
      "Epoch 25, CIFAR-10 Batch 1:  \n",
      "Loss = 0.42258310317993164 \t Accuracy = 0.5507999658584595\n",
      "\n",
      "Epoch 26, CIFAR-10 Batch 1:  \n",
      "Loss = 0.39227259159088135 \t Accuracy = 0.5603998899459839\n",
      "\n",
      "Epoch 27, CIFAR-10 Batch 1:  \n",
      "Loss = 0.3616177439689636 \t Accuracy = 0.5783998966217041\n",
      "\n",
      "Epoch 28, CIFAR-10 Batch 1:  \n",
      "Loss = 0.3525674343109131 \t Accuracy = 0.5691999197006226\n",
      "\n",
      "Epoch 29, CIFAR-10 Batch 1:  \n",
      "Loss = 0.33910268545150757 \t Accuracy = 0.5829999446868896\n",
      "\n",
      "Epoch 30, CIFAR-10 Batch 1:  \n",
      "Loss = 0.34103530645370483 \t Accuracy = 0.5639999508857727\n",
      "\n",
      "Epoch 31, CIFAR-10 Batch 1:  \n",
      "Loss = 0.3230723738670349 \t Accuracy = 0.5819998979568481\n",
      "\n",
      "Epoch 32, CIFAR-10 Batch 1:  \n",
      "Loss = 0.31848612427711487 \t Accuracy = 0.5831999778747559\n",
      "\n",
      "Epoch 33, CIFAR-10 Batch 1:  \n",
      "Loss = 0.31631335616111755 \t Accuracy = 0.5903999209403992\n",
      "\n",
      "Epoch 34, CIFAR-10 Batch 1:  \n",
      "Loss = 0.3145085573196411 \t Accuracy = 0.5837999582290649\n",
      "\n",
      "Epoch 35, CIFAR-10 Batch 1:  \n",
      "Loss = 0.305993914604187 \t Accuracy = 0.584399938583374\n",
      "\n",
      "Epoch 36, CIFAR-10 Batch 1:  \n",
      "Loss = 0.3121511936187744 \t Accuracy = 0.571199893951416\n",
      "\n",
      "Epoch 37, CIFAR-10 Batch 1:  \n",
      "Loss = 0.3101148307323456 \t Accuracy = 0.5749999284744263\n",
      "\n",
      "Epoch 38, CIFAR-10 Batch 1:  \n",
      "Loss = 0.2650505006313324 \t Accuracy = 0.5619999170303345\n",
      "\n",
      "Epoch 39, CIFAR-10 Batch 1:  \n",
      "Loss = 0.2514810860157013 \t Accuracy = 0.5859999060630798\n",
      "\n",
      "Epoch 40, CIFAR-10 Batch 1:  \n",
      "Loss = 0.22315098345279694 \t Accuracy = 0.5775999426841736\n",
      "\n",
      "Epoch 41, CIFAR-10 Batch 1:  \n",
      "Loss = 0.21868544816970825 \t Accuracy = 0.5829999446868896\n",
      "\n",
      "Epoch 42, CIFAR-10 Batch 1:  \n",
      "Loss = 0.23122495412826538 \t Accuracy = 0.5691999197006226\n",
      "\n",
      "Epoch 43, CIFAR-10 Batch 1:  \n",
      "Loss = 0.20353050529956818 \t Accuracy = 0.5933998823165894\n",
      "\n",
      "Epoch 44, CIFAR-10 Batch 1:  \n",
      "Loss = 0.18829184770584106 \t Accuracy = 0.5727999210357666\n",
      "\n",
      "Epoch 45, CIFAR-10 Batch 1:  \n",
      "Loss = 0.2134835124015808 \t Accuracy = 0.5781999230384827\n",
      "\n",
      "Epoch 46, CIFAR-10 Batch 1:  \n",
      "Loss = 0.19344472885131836 \t Accuracy = 0.58079993724823\n",
      "\n",
      "Epoch 47, CIFAR-10 Batch 1:  \n",
      "Loss = 0.1776021271944046 \t Accuracy = 0.577799916267395\n",
      "\n",
      "Epoch 48, CIFAR-10 Batch 1:  \n",
      "Loss = 0.16894488036632538 \t Accuracy = 0.5885999798774719\n",
      "\n",
      "Epoch 49, CIFAR-10 Batch 1:  \n",
      "Loss = 0.16530919075012207 \t Accuracy = 0.5871999859809875\n",
      "\n",
      "Epoch 50, CIFAR-10 Batch 1:  \n",
      "Loss = 0.15356546640396118 \t Accuracy = 0.5867999196052551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  \n",
      "Loss = 2.226828098297119 \t Accuracy = 0.2223999798297882\n",
      "\n",
      "Epoch  1, CIFAR-10 Batch 2:  \n",
      "Loss = 2.142465591430664 \t Accuracy = 0.32739999890327454\n",
      "\n",
      "Epoch  1, CIFAR-10 Batch 3:  \n",
      "Loss = 1.7371060848236084 \t Accuracy = 0.3935999572277069\n",
      "\n",
      "Epoch  1, CIFAR-10 Batch 4:  \n",
      "Loss = 1.4037481546401978 \t Accuracy = 0.4609999656677246\n",
      "\n",
      "Epoch  1, CIFAR-10 Batch 5:  \n",
      "Loss = 1.3912630081176758 \t Accuracy = 0.4763999581336975\n",
      "\n",
      "Epoch  2, CIFAR-10 Batch 1:  \n",
      "Loss = 1.3694254159927368 \t Accuracy = 0.5197999477386475\n",
      "\n",
      "Epoch  2, CIFAR-10 Batch 2:  \n",
      "Loss = 1.208749771118164 \t Accuracy = 0.5163999199867249\n",
      "\n",
      "Epoch  2, CIFAR-10 Batch 3:  \n",
      "Loss = 1.0307714939117432 \t Accuracy = 0.5359998941421509\n",
      "\n",
      "Epoch  2, CIFAR-10 Batch 4:  \n",
      "Loss = 1.150298833847046 \t Accuracy = 0.5513999462127686\n",
      "\n",
      "Epoch  2, CIFAR-10 Batch 5:  \n",
      "Loss = 1.0815598964691162 \t Accuracy = 0.5369999408721924\n",
      "\n",
      "Epoch  3, CIFAR-10 Batch 1:  \n",
      "Loss = 1.1407392024993896 \t Accuracy = 0.5353999137878418\n",
      "\n",
      "Epoch  3, CIFAR-10 Batch 2:  \n",
      "Loss = 0.9820795059204102 \t Accuracy = 0.5561999082565308\n",
      "\n",
      "Epoch  3, CIFAR-10 Batch 3:  \n",
      "Loss = 0.8169845938682556 \t Accuracy = 0.5619999170303345\n",
      "\n",
      "Epoch  3, CIFAR-10 Batch 4:  \n",
      "Loss = 0.9469867944717407 \t Accuracy = 0.5841999053955078\n",
      "\n",
      "Epoch  3, CIFAR-10 Batch 5:  \n",
      "Loss = 0.8498116135597229 \t Accuracy = 0.5889999270439148\n",
      "\n",
      "Epoch  4, CIFAR-10 Batch 1:  \n",
      "Loss = 0.9365100264549255 \t Accuracy = 0.5771999359130859\n",
      "\n",
      "Epoch  4, CIFAR-10 Batch 2:  \n",
      "Loss = 0.9178769588470459 \t Accuracy = 0.5965999364852905\n",
      "\n",
      "Epoch  4, CIFAR-10 Batch 3:  \n",
      "Loss = 0.6681605577468872 \t Accuracy = 0.5907999277114868\n",
      "\n",
      "Epoch  4, CIFAR-10 Batch 4:  \n",
      "Loss = 0.7981483936309814 \t Accuracy = 0.6101998686790466\n",
      "\n",
      "Epoch  4, CIFAR-10 Batch 5:  \n",
      "Loss = 0.7666750550270081 \t Accuracy = 0.608799934387207\n",
      "\n",
      "Epoch  5, CIFAR-10 Batch 1:  \n",
      "Loss = 0.8522201776504517 \t Accuracy = 0.5935999751091003\n",
      "\n",
      "Epoch  5, CIFAR-10 Batch 2:  \n",
      "Loss = 0.8377611637115479 \t Accuracy = 0.6103999018669128\n",
      "\n",
      "Epoch  5, CIFAR-10 Batch 3:  \n",
      "Loss = 0.555867612361908 \t Accuracy = 0.6035999059677124\n",
      "\n",
      "Epoch  5, CIFAR-10 Batch 4:  \n",
      "Loss = 0.7037838101387024 \t Accuracy = 0.6129999160766602\n",
      "\n",
      "Epoch  5, CIFAR-10 Batch 5:  \n",
      "Loss = 0.6744606494903564 \t Accuracy = 0.6225998997688293\n",
      "\n",
      "Epoch  6, CIFAR-10 Batch 1:  \n",
      "Loss = 0.7630150318145752 \t Accuracy = 0.6087998747825623\n",
      "\n",
      "Epoch  6, CIFAR-10 Batch 2:  \n",
      "Loss = 0.7529576420783997 \t Accuracy = 0.6299998760223389\n",
      "\n",
      "Epoch  6, CIFAR-10 Batch 3:  \n",
      "Loss = 0.4597442150115967 \t Accuracy = 0.6245999336242676\n",
      "\n",
      "Epoch  6, CIFAR-10 Batch 4:  \n",
      "Loss = 0.6383571624755859 \t Accuracy = 0.6381999254226685\n",
      "\n",
      "Epoch  6, CIFAR-10 Batch 5:  \n",
      "Loss = 0.6357976198196411 \t Accuracy = 0.6253999471664429\n",
      "\n",
      "Epoch  7, CIFAR-10 Batch 1:  \n",
      "Loss = 0.6758633852005005 \t Accuracy = 0.6241999268531799\n",
      "\n",
      "Epoch  7, CIFAR-10 Batch 2:  \n",
      "Loss = 0.6171267628669739 \t Accuracy = 0.6393998861312866\n",
      "\n",
      "Epoch  7, CIFAR-10 Batch 3:  \n",
      "Loss = 0.38118794560432434 \t Accuracy = 0.6355998516082764\n",
      "\n",
      "Epoch  7, CIFAR-10 Batch 4:  \n",
      "Loss = 0.5310893058776855 \t Accuracy = 0.6401999592781067\n",
      "\n",
      "Epoch  7, CIFAR-10 Batch 5:  \n",
      "Loss = 0.599563479423523 \t Accuracy = 0.642599880695343\n",
      "\n",
      "Epoch  8, CIFAR-10 Batch 1:  \n",
      "Loss = 0.6437556743621826 \t Accuracy = 0.6369999051094055\n",
      "\n",
      "Epoch  8, CIFAR-10 Batch 2:  \n",
      "Loss = 0.5182835459709167 \t Accuracy = 0.6449999213218689\n",
      "\n",
      "Epoch  8, CIFAR-10 Batch 3:  \n",
      "Loss = 0.31885212659835815 \t Accuracy = 0.6429998874664307\n",
      "\n",
      "Epoch  8, CIFAR-10 Batch 4:  \n",
      "Loss = 0.5170347690582275 \t Accuracy = 0.6411998867988586\n",
      "\n",
      "Epoch  8, CIFAR-10 Batch 5:  \n",
      "Loss = 0.521730363368988 \t Accuracy = 0.6435999274253845\n",
      "\n",
      "Epoch  9, CIFAR-10 Batch 1:  \n",
      "Loss = 0.5786386728286743 \t Accuracy = 0.6413998603820801\n",
      "\n",
      "Epoch  9, CIFAR-10 Batch 2:  \n",
      "Loss = 0.4966821074485779 \t Accuracy = 0.6405999064445496\n",
      "\n",
      "Epoch  9, CIFAR-10 Batch 3:  \n",
      "Loss = 0.33056873083114624 \t Accuracy = 0.6373999118804932\n",
      "\n",
      "Epoch  9, CIFAR-10 Batch 4:  \n",
      "Loss = 0.3914240598678589 \t Accuracy = 0.6547998785972595\n",
      "\n",
      "Epoch  9, CIFAR-10 Batch 5:  \n",
      "Loss = 0.524468183517456 \t Accuracy = 0.6453999280929565\n",
      "\n",
      "Epoch 10, CIFAR-10 Batch 1:  \n",
      "Loss = 0.529377818107605 \t Accuracy = 0.6521998643875122\n",
      "\n",
      "Epoch 10, CIFAR-10 Batch 2:  \n",
      "Loss = 0.43049824237823486 \t Accuracy = 0.6553999185562134\n",
      "\n",
      "Epoch 10, CIFAR-10 Batch 3:  \n",
      "Loss = 0.2660086750984192 \t Accuracy = 0.642599880695343\n",
      "\n",
      "Epoch 10, CIFAR-10 Batch 4:  \n",
      "Loss = 0.39634978771209717 \t Accuracy = 0.6525999307632446\n",
      "\n",
      "Epoch 10, CIFAR-10 Batch 5:  \n",
      "Loss = 0.45197632908821106 \t Accuracy = 0.6543998718261719\n",
      "\n",
      "Epoch 11, CIFAR-10 Batch 1:  \n",
      "Loss = 0.5086371302604675 \t Accuracy = 0.6541998386383057\n",
      "\n",
      "Epoch 11, CIFAR-10 Batch 2:  \n",
      "Loss = 0.3917161822319031 \t Accuracy = 0.6489999294281006\n",
      "\n",
      "Epoch 11, CIFAR-10 Batch 3:  \n",
      "Loss = 0.24852192401885986 \t Accuracy = 0.6499999165534973\n",
      "\n",
      "Epoch 11, CIFAR-10 Batch 4:  \n",
      "Loss = 0.3563941717147827 \t Accuracy = 0.6597998738288879\n",
      "\n",
      "Epoch 11, CIFAR-10 Batch 5:  \n",
      "Loss = 0.3980303704738617 \t Accuracy = 0.6551998257637024\n",
      "\n",
      "Epoch 12, CIFAR-10 Batch 1:  \n",
      "Loss = 0.4714454114437103 \t Accuracy = 0.6529999375343323\n",
      "\n",
      "Epoch 12, CIFAR-10 Batch 2:  \n",
      "Loss = 0.37233036756515503 \t Accuracy = 0.6571998596191406\n",
      "\n",
      "Epoch 12, CIFAR-10 Batch 3:  \n",
      "Loss = 0.21770048141479492 \t Accuracy = 0.6465998888015747\n",
      "\n",
      "Epoch 12, CIFAR-10 Batch 4:  \n",
      "Loss = 0.3432398736476898 \t Accuracy = 0.6531999111175537\n",
      "\n",
      "Epoch 12, CIFAR-10 Batch 5:  \n",
      "Loss = 0.3377458453178406 \t Accuracy = 0.6661998629570007\n",
      "\n",
      "Epoch 13, CIFAR-10 Batch 1:  \n",
      "Loss = 0.4312901198863983 \t Accuracy = 0.6531999111175537\n",
      "\n",
      "Epoch 13, CIFAR-10 Batch 2:  \n",
      "Loss = 0.3662668764591217 \t Accuracy = 0.6553999185562134\n",
      "\n",
      "Epoch 13, CIFAR-10 Batch 3:  \n",
      "Loss = 0.1904580295085907 \t Accuracy = 0.650999903678894\n",
      "\n",
      "Epoch 13, CIFAR-10 Batch 4:  \n",
      "Loss = 0.2878340780735016 \t Accuracy = 0.6613998413085938\n",
      "\n",
      "Epoch 13, CIFAR-10 Batch 5:  \n",
      "Loss = 0.29979848861694336 \t Accuracy = 0.6659998893737793\n",
      "\n",
      "Epoch 14, CIFAR-10 Batch 1:  \n",
      "Loss = 0.4916490912437439 \t Accuracy = 0.6557998657226562\n",
      "\n",
      "Epoch 14, CIFAR-10 Batch 2:  \n",
      "Loss = 0.28420665860176086 \t Accuracy = 0.6633999347686768\n",
      "\n",
      "Epoch 14, CIFAR-10 Batch 3:  \n",
      "Loss = 0.2011314183473587 \t Accuracy = 0.6653998494148254\n",
      "\n",
      "Epoch 14, CIFAR-10 Batch 4:  \n",
      "Loss = 0.2650637626647949 \t Accuracy = 0.6625999212265015\n",
      "\n",
      "Epoch 14, CIFAR-10 Batch 5:  \n",
      "Loss = 0.28297168016433716 \t Accuracy = 0.6679998636245728\n",
      "\n",
      "Epoch 15, CIFAR-10 Batch 1:  \n",
      "Loss = 0.42373424768447876 \t Accuracy = 0.6563998460769653\n",
      "\n",
      "Epoch 15, CIFAR-10 Batch 2:  \n",
      "Loss = 0.3003735840320587 \t Accuracy = 0.6597998738288879\n",
      "\n",
      "Epoch 15, CIFAR-10 Batch 3:  \n",
      "Loss = 0.17198915779590607 \t Accuracy = 0.6565998792648315\n",
      "\n",
      "Epoch 15, CIFAR-10 Batch 4:  \n",
      "Loss = 0.22966121137142181 \t Accuracy = 0.6643999218940735\n",
      "\n",
      "Epoch 15, CIFAR-10 Batch 5:  \n",
      "Loss = 0.26177680492401123 \t Accuracy = 0.6761999130249023\n",
      "\n",
      "Epoch 16, CIFAR-10 Batch 1:  \n",
      "Loss = 0.42539265751838684 \t Accuracy = 0.6501998901367188\n",
      "\n",
      "Epoch 16, CIFAR-10 Batch 2:  \n",
      "Loss = 0.23831476271152496 \t Accuracy = 0.6617999076843262\n",
      "\n",
      "Epoch 16, CIFAR-10 Batch 3:  \n",
      "Loss = 0.1419363021850586 \t Accuracy = 0.6691998839378357\n",
      "\n",
      "Epoch 16, CIFAR-10 Batch 4:  \n",
      "Loss = 0.24046853184700012 \t Accuracy = 0.6649998426437378\n",
      "\n",
      "Epoch 16, CIFAR-10 Batch 5:  \n",
      "Loss = 0.2858341932296753 \t Accuracy = 0.6695998311042786\n",
      "\n",
      "Epoch 17, CIFAR-10 Batch 1:  \n",
      "Loss = 0.3867845833301544 \t Accuracy = 0.6563999056816101\n",
      "\n",
      "Epoch 17, CIFAR-10 Batch 2:  \n",
      "Loss = 0.2283160388469696 \t Accuracy = 0.6649999022483826\n",
      "\n",
      "Epoch 17, CIFAR-10 Batch 3:  \n",
      "Loss = 0.14157521724700928 \t Accuracy = 0.6653998494148254\n",
      "\n",
      "Epoch 17, CIFAR-10 Batch 4:  \n",
      "Loss = 0.22267897427082062 \t Accuracy = 0.6647998690605164\n",
      "\n",
      "Epoch 17, CIFAR-10 Batch 5:  \n",
      "Loss = 0.2527850270271301 \t Accuracy = 0.6791998744010925\n",
      "\n",
      "Epoch 18, CIFAR-10 Batch 1:  \n",
      "Loss = 0.35196635127067566 \t Accuracy = 0.6663998365402222\n",
      "\n",
      "Epoch 18, CIFAR-10 Batch 2:  \n",
      "Loss = 0.24770991504192352 \t Accuracy = 0.6667999029159546\n",
      "\n",
      "Epoch 18, CIFAR-10 Batch 3:  \n",
      "Loss = 0.16117636859416962 \t Accuracy = 0.6643998622894287\n",
      "\n",
      "Epoch 18, CIFAR-10 Batch 4:  \n",
      "Loss = 0.21736516058444977 \t Accuracy = 0.6599999070167542\n",
      "\n",
      "Epoch 18, CIFAR-10 Batch 5:  \n",
      "Loss = 0.21360523998737335 \t Accuracy = 0.674799919128418\n",
      "\n",
      "Epoch 19, CIFAR-10 Batch 1:  \n",
      "Loss = 0.35279160737991333 \t Accuracy = 0.6693999171257019\n",
      "\n",
      "Epoch 19, CIFAR-10 Batch 2:  \n",
      "Loss = 0.21401259303092957 \t Accuracy = 0.663399875164032\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, CIFAR-10 Batch 3:  \n",
      "Loss = 0.1544664204120636 \t Accuracy = 0.6599999666213989\n",
      "\n",
      "Epoch 19, CIFAR-10 Batch 4:  \n",
      "Loss = 0.17480967938899994 \t Accuracy = 0.6713999509811401\n",
      "\n",
      "Epoch 19, CIFAR-10 Batch 5:  \n",
      "Loss = 0.20612047612667084 \t Accuracy = 0.6755998134613037\n",
      "\n",
      "Epoch 20, CIFAR-10 Batch 1:  \n",
      "Loss = 0.3887079358100891 \t Accuracy = 0.6643998622894287\n",
      "\n",
      "Epoch 20, CIFAR-10 Batch 2:  \n",
      "Loss = 0.15177638828754425 \t Accuracy = 0.6631999015808105\n",
      "\n",
      "Epoch 20, CIFAR-10 Batch 3:  \n",
      "Loss = 0.1371917426586151 \t Accuracy = 0.6733999252319336\n",
      "\n",
      "Epoch 20, CIFAR-10 Batch 4:  \n",
      "Loss = 0.18005618453025818 \t Accuracy = 0.6819998025894165\n",
      "\n",
      "Epoch 20, CIFAR-10 Batch 5:  \n",
      "Loss = 0.19977852702140808 \t Accuracy = 0.6743998527526855\n",
      "\n",
      "Epoch 21, CIFAR-10 Batch 1:  \n",
      "Loss = 0.32881438732147217 \t Accuracy = 0.6761999130249023\n",
      "\n",
      "Epoch 21, CIFAR-10 Batch 2:  \n",
      "Loss = 0.16643789410591125 \t Accuracy = 0.6627998948097229\n",
      "\n",
      "Epoch 21, CIFAR-10 Batch 3:  \n",
      "Loss = 0.13053478300571442 \t Accuracy = 0.6591998934745789\n",
      "\n",
      "Epoch 21, CIFAR-10 Batch 4:  \n",
      "Loss = 0.16282868385314941 \t Accuracy = 0.6765998601913452\n",
      "\n",
      "Epoch 21, CIFAR-10 Batch 5:  \n",
      "Loss = 0.1849234700202942 \t Accuracy = 0.6753998398780823\n",
      "\n",
      "Epoch 22, CIFAR-10 Batch 1:  \n",
      "Loss = 0.31145763397216797 \t Accuracy = 0.6655998229980469\n",
      "\n",
      "Epoch 22, CIFAR-10 Batch 2:  \n",
      "Loss = 0.1471632570028305 \t Accuracy = 0.6631998419761658\n",
      "\n",
      "Epoch 22, CIFAR-10 Batch 3:  \n",
      "Loss = 0.12331882119178772 \t Accuracy = 0.6769999265670776\n",
      "\n",
      "Epoch 22, CIFAR-10 Batch 4:  \n",
      "Loss = 0.14408907294273376 \t Accuracy = 0.676399827003479\n",
      "\n",
      "Epoch 22, CIFAR-10 Batch 5:  \n",
      "Loss = 0.16023695468902588 \t Accuracy = 0.679999828338623\n",
      "\n",
      "Epoch 23, CIFAR-10 Batch 1:  \n",
      "Loss = 0.26670554280281067 \t Accuracy = 0.6699998378753662\n",
      "\n",
      "Epoch 23, CIFAR-10 Batch 2:  \n",
      "Loss = 0.1660071462392807 \t Accuracy = 0.6595999002456665\n",
      "\n",
      "Epoch 23, CIFAR-10 Batch 3:  \n",
      "Loss = 0.1462607979774475 \t Accuracy = 0.6597998738288879\n",
      "\n",
      "Epoch 23, CIFAR-10 Batch 4:  \n",
      "Loss = 0.1439509242773056 \t Accuracy = 0.6749998927116394\n",
      "\n",
      "Epoch 23, CIFAR-10 Batch 5:  \n",
      "Loss = 0.16274350881576538 \t Accuracy = 0.6743998527526855\n",
      "\n",
      "Epoch 24, CIFAR-10 Batch 1:  \n",
      "Loss = 0.2505331039428711 \t Accuracy = 0.6779999136924744\n",
      "\n",
      "Epoch 24, CIFAR-10 Batch 2:  \n",
      "Loss = 0.14147379994392395 \t Accuracy = 0.6647998690605164\n",
      "\n",
      "Epoch 24, CIFAR-10 Batch 3:  \n",
      "Loss = 0.10695381462574005 \t Accuracy = 0.6733999252319336\n",
      "\n",
      "Epoch 24, CIFAR-10 Batch 4:  \n",
      "Loss = 0.16678546369075775 \t Accuracy = 0.6739999055862427\n",
      "\n",
      "Epoch 24, CIFAR-10 Batch 5:  \n",
      "Loss = 0.17210817337036133 \t Accuracy = 0.6837998628616333\n",
      "\n",
      "Epoch 25, CIFAR-10 Batch 1:  \n",
      "Loss = 0.2688602805137634 \t Accuracy = 0.6627998948097229\n",
      "\n",
      "Epoch 25, CIFAR-10 Batch 2:  \n",
      "Loss = 0.11906387656927109 \t Accuracy = 0.6679998636245728\n",
      "\n",
      "Epoch 25, CIFAR-10 Batch 3:  \n",
      "Loss = 0.09846644103527069 \t Accuracy = 0.6779997944831848\n",
      "\n",
      "Epoch 25, CIFAR-10 Batch 4:  \n",
      "Loss = 0.1596260964870453 \t Accuracy = 0.6759998798370361\n",
      "\n",
      "Epoch 25, CIFAR-10 Batch 5:  \n",
      "Loss = 0.16789957880973816 \t Accuracy = 0.6771999001502991\n",
      "\n",
      "Epoch 26, CIFAR-10 Batch 1:  \n",
      "Loss = 0.25073808431625366 \t Accuracy = 0.6693999171257019\n",
      "\n",
      "Epoch 26, CIFAR-10 Batch 2:  \n",
      "Loss = 0.16279885172843933 \t Accuracy = 0.6697999238967896\n",
      "\n",
      "Epoch 26, CIFAR-10 Batch 3:  \n",
      "Loss = 0.10615172982215881 \t Accuracy = 0.672999918460846\n",
      "\n",
      "Epoch 26, CIFAR-10 Batch 4:  \n",
      "Loss = 0.14848312735557556 \t Accuracy = 0.6731998920440674\n",
      "\n",
      "Epoch 26, CIFAR-10 Batch 5:  \n",
      "Loss = 0.16983148455619812 \t Accuracy = 0.6763998866081238\n",
      "\n",
      "Epoch 27, CIFAR-10 Batch 1:  \n",
      "Loss = 0.21363642811775208 \t Accuracy = 0.6697998642921448\n",
      "\n",
      "Epoch 27, CIFAR-10 Batch 2:  \n",
      "Loss = 0.11886400729417801 \t Accuracy = 0.672799825668335\n",
      "\n",
      "Epoch 27, CIFAR-10 Batch 3:  \n",
      "Loss = 0.13700267672538757 \t Accuracy = 0.6571999192237854\n",
      "\n",
      "Epoch 27, CIFAR-10 Batch 4:  \n",
      "Loss = 0.13920597732067108 \t Accuracy = 0.6845998764038086\n",
      "\n",
      "Epoch 27, CIFAR-10 Batch 5:  \n",
      "Loss = 0.17421714961528778 \t Accuracy = 0.6681998372077942\n",
      "\n",
      "Epoch 28, CIFAR-10 Batch 1:  \n",
      "Loss = 0.23210252821445465 \t Accuracy = 0.6727998852729797\n",
      "\n",
      "Epoch 28, CIFAR-10 Batch 2:  \n",
      "Loss = 0.12634699046611786 \t Accuracy = 0.6689999103546143\n",
      "\n",
      "Epoch 28, CIFAR-10 Batch 3:  \n",
      "Loss = 0.10446207970380783 \t Accuracy = 0.6719998121261597\n",
      "\n",
      "Epoch 28, CIFAR-10 Batch 4:  \n",
      "Loss = 0.14044073224067688 \t Accuracy = 0.6771998405456543\n",
      "\n",
      "Epoch 28, CIFAR-10 Batch 5:  \n",
      "Loss = 0.17984306812286377 \t Accuracy = 0.668199896812439\n",
      "\n",
      "Epoch 29, CIFAR-10 Batch 1:  \n",
      "Loss = 0.21832264959812164 \t Accuracy = 0.679399847984314\n",
      "\n",
      "Epoch 29, CIFAR-10 Batch 2:  \n",
      "Loss = 0.13915090262889862 \t Accuracy = 0.6673998832702637\n",
      "\n",
      "Epoch 29, CIFAR-10 Batch 3:  \n",
      "Loss = 0.10274717211723328 \t Accuracy = 0.6719999313354492\n",
      "\n",
      "Epoch 29, CIFAR-10 Batch 4:  \n",
      "Loss = 0.1465429961681366 \t Accuracy = 0.6801998615264893\n",
      "\n",
      "Epoch 29, CIFAR-10 Batch 5:  \n",
      "Loss = 0.13493311405181885 \t Accuracy = 0.6759998202323914\n",
      "\n",
      "Epoch 30, CIFAR-10 Batch 1:  \n",
      "Loss = 0.19035004079341888 \t Accuracy = 0.6825999021530151\n",
      "\n",
      "Epoch 30, CIFAR-10 Batch 2:  \n",
      "Loss = 0.1104421466588974 \t Accuracy = 0.668199896812439\n",
      "\n",
      "Epoch 30, CIFAR-10 Batch 3:  \n",
      "Loss = 0.06516216695308685 \t Accuracy = 0.6811999082565308\n",
      "\n",
      "Epoch 30, CIFAR-10 Batch 4:  \n",
      "Loss = 0.13083001971244812 \t Accuracy = 0.687799870967865\n",
      "\n",
      "Epoch 30, CIFAR-10 Batch 5:  \n",
      "Loss = 0.1327570378780365 \t Accuracy = 0.6721999049186707\n",
      "\n",
      "Epoch 31, CIFAR-10 Batch 1:  \n",
      "Loss = 0.200786754488945 \t Accuracy = 0.678199827671051\n",
      "\n",
      "Epoch 31, CIFAR-10 Batch 2:  \n",
      "Loss = 0.09316018968820572 \t Accuracy = 0.6765998601913452\n",
      "\n",
      "Epoch 31, CIFAR-10 Batch 3:  \n",
      "Loss = 0.0741945132613182 \t Accuracy = 0.6759998798370361\n",
      "\n",
      "Epoch 31, CIFAR-10 Batch 4:  \n",
      "Loss = 0.10659829527139664 \t Accuracy = 0.6817998290061951\n",
      "\n",
      "Epoch 31, CIFAR-10 Batch 5:  \n",
      "Loss = 0.12751060724258423 \t Accuracy = 0.6599999070167542\n",
      "\n",
      "Epoch 32, CIFAR-10 Batch 1:  \n",
      "Loss = 0.20740588009357452 \t Accuracy = 0.672999918460846\n",
      "\n",
      "Epoch 32, CIFAR-10 Batch 2:  \n",
      "Loss = 0.10925839096307755 \t Accuracy = 0.6737999320030212\n",
      "\n",
      "Epoch 32, CIFAR-10 Batch 3:  \n",
      "Loss = 0.07233987748622894 \t Accuracy = 0.6735998392105103\n",
      "\n",
      "Epoch 32, CIFAR-10 Batch 4:  \n",
      "Loss = 0.09927056729793549 \t Accuracy = 0.6849998235702515\n",
      "\n",
      "Epoch 32, CIFAR-10 Batch 5:  \n",
      "Loss = 0.11732935160398483 \t Accuracy = 0.6769999265670776\n",
      "\n",
      "Epoch 33, CIFAR-10 Batch 1:  \n",
      "Loss = 0.15791773796081543 \t Accuracy = 0.6825999021530151\n",
      "\n",
      "Epoch 33, CIFAR-10 Batch 2:  \n",
      "Loss = 0.07132770866155624 \t Accuracy = 0.675399899482727\n",
      "\n",
      "Epoch 33, CIFAR-10 Batch 3:  \n",
      "Loss = 0.0512123703956604 \t Accuracy = 0.6635998487472534\n",
      "\n",
      "Epoch 33, CIFAR-10 Batch 4:  \n",
      "Loss = 0.10475465655326843 \t Accuracy = 0.6801998615264893\n",
      "\n",
      "Epoch 33, CIFAR-10 Batch 5:  \n",
      "Loss = 0.12831281125545502 \t Accuracy = 0.674799919128418\n",
      "\n",
      "Epoch 34, CIFAR-10 Batch 1:  \n",
      "Loss = 0.15968270599842072 \t Accuracy = 0.6789998412132263\n",
      "\n",
      "Epoch 34, CIFAR-10 Batch 2:  \n",
      "Loss = 0.08466503024101257 \t Accuracy = 0.671799898147583\n",
      "\n",
      "Epoch 34, CIFAR-10 Batch 3:  \n",
      "Loss = 0.07388943433761597 \t Accuracy = 0.6725998520851135\n",
      "\n",
      "Epoch 34, CIFAR-10 Batch 4:  \n",
      "Loss = 0.07998089492321014 \t Accuracy = 0.6845998764038086\n",
      "\n",
      "Epoch 34, CIFAR-10 Batch 5:  \n",
      "Loss = 0.13379526138305664 \t Accuracy = 0.6769999265670776\n",
      "\n",
      "Epoch 35, CIFAR-10 Batch 1:  \n",
      "Loss = 0.14465218782424927 \t Accuracy = 0.6807999014854431\n",
      "\n",
      "Epoch 35, CIFAR-10 Batch 2:  \n",
      "Loss = 0.08800958096981049 \t Accuracy = 0.6791998744010925\n",
      "\n",
      "Epoch 35, CIFAR-10 Batch 3:  \n",
      "Loss = 0.06598283350467682 \t Accuracy = 0.6649999022483826\n",
      "\n",
      "Epoch 35, CIFAR-10 Batch 4:  \n",
      "Loss = 0.10067339241504669 \t Accuracy = 0.6813998818397522\n",
      "\n",
      "Epoch 35, CIFAR-10 Batch 5:  \n",
      "Loss = 0.11136709898710251 \t Accuracy = 0.6827998757362366\n",
      "\n",
      "Epoch 36, CIFAR-10 Batch 1:  \n",
      "Loss = 0.14591442048549652 \t Accuracy = 0.6717999577522278\n",
      "\n",
      "Epoch 36, CIFAR-10 Batch 2:  \n",
      "Loss = 0.08761873841285706 \t Accuracy = 0.6673999428749084\n",
      "\n",
      "Epoch 36, CIFAR-10 Batch 3:  \n",
      "Loss = 0.06429260969161987 \t Accuracy = 0.6649998426437378\n",
      "\n",
      "Epoch 36, CIFAR-10 Batch 4:  \n",
      "Loss = 0.1008157879114151 \t Accuracy = 0.6835998296737671\n",
      "\n",
      "Epoch 36, CIFAR-10 Batch 5:  \n",
      "Loss = 0.1158512607216835 \t Accuracy = 0.6781998872756958\n",
      "\n",
      "Epoch 37, CIFAR-10 Batch 1:  \n",
      "Loss = 0.14268705248832703 \t Accuracy = 0.6825999021530151\n",
      "\n",
      "Epoch 37, CIFAR-10 Batch 2:  \n",
      "Loss = 0.08197617530822754 \t Accuracy = 0.673599898815155\n",
      "\n",
      "Epoch 37, CIFAR-10 Batch 3:  \n",
      "Loss = 0.0405852310359478 \t Accuracy = 0.6767999529838562\n",
      "\n",
      "Epoch 37, CIFAR-10 Batch 4:  \n",
      "Loss = 0.09166226536035538 \t Accuracy = 0.6803998351097107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, CIFAR-10 Batch 5:  \n",
      "Loss = 0.09950610995292664 \t Accuracy = 0.6807999014854431\n",
      "\n",
      "Epoch 38, CIFAR-10 Batch 1:  \n",
      "Loss = 0.1402876377105713 \t Accuracy = 0.6837998628616333\n",
      "\n",
      "Epoch 38, CIFAR-10 Batch 2:  \n",
      "Loss = 0.08738011866807938 \t Accuracy = 0.673599898815155\n",
      "\n",
      "Epoch 38, CIFAR-10 Batch 3:  \n",
      "Loss = 0.04615015536546707 \t Accuracy = 0.6637998819351196\n",
      "\n",
      "Epoch 38, CIFAR-10 Batch 4:  \n",
      "Loss = 0.07257343083620071 \t Accuracy = 0.6795998811721802\n",
      "\n",
      "Epoch 38, CIFAR-10 Batch 5:  \n",
      "Loss = 0.11671626567840576 \t Accuracy = 0.678199827671051\n",
      "\n",
      "Epoch 39, CIFAR-10 Batch 1:  \n",
      "Loss = 0.13374467194080353 \t Accuracy = 0.68479984998703\n",
      "\n",
      "Epoch 39, CIFAR-10 Batch 2:  \n",
      "Loss = 0.06286300718784332 \t Accuracy = 0.6809998750686646\n",
      "\n",
      "Epoch 39, CIFAR-10 Batch 3:  \n",
      "Loss = 0.03512461856007576 \t Accuracy = 0.6727998852729797\n",
      "\n",
      "Epoch 39, CIFAR-10 Batch 4:  \n",
      "Loss = 0.08029882609844208 \t Accuracy = 0.6835998296737671\n",
      "\n",
      "Epoch 39, CIFAR-10 Batch 5:  \n",
      "Loss = 0.10099226236343384 \t Accuracy = 0.6841998100280762\n",
      "\n",
      "Epoch 40, CIFAR-10 Batch 1:  \n",
      "Loss = 0.13808907568454742 \t Accuracy = 0.6845999360084534\n",
      "\n",
      "Epoch 40, CIFAR-10 Batch 2:  \n",
      "Loss = 0.07295135408639908 \t Accuracy = 0.6763998866081238\n",
      "\n",
      "Epoch 40, CIFAR-10 Batch 3:  \n",
      "Loss = 0.0459606759250164 \t Accuracy = 0.6593998670578003\n",
      "\n",
      "Epoch 40, CIFAR-10 Batch 4:  \n",
      "Loss = 0.06577380001544952 \t Accuracy = 0.681999921798706\n",
      "\n",
      "Epoch 40, CIFAR-10 Batch 5:  \n",
      "Loss = 0.09216998517513275 \t Accuracy = 0.6869997978210449\n",
      "\n",
      "Epoch 41, CIFAR-10 Batch 1:  \n",
      "Loss = 0.12319055944681168 \t Accuracy = 0.6767998337745667\n",
      "\n",
      "Epoch 41, CIFAR-10 Batch 2:  \n",
      "Loss = 0.06994608789682388 \t Accuracy = 0.6757998466491699\n",
      "\n",
      "Epoch 41, CIFAR-10 Batch 3:  \n",
      "Loss = 0.05839567631483078 \t Accuracy = 0.6607998609542847\n",
      "\n",
      "Epoch 41, CIFAR-10 Batch 4:  \n",
      "Loss = 0.05716267228126526 \t Accuracy = 0.6769998669624329\n",
      "\n",
      "Epoch 41, CIFAR-10 Batch 5:  \n",
      "Loss = 0.10487009584903717 \t Accuracy = 0.6835998296737671\n",
      "\n",
      "Epoch 42, CIFAR-10 Batch 1:  \n",
      "Loss = 0.11961254477500916 \t Accuracy = 0.679999828338623\n",
      "\n",
      "Epoch 42, CIFAR-10 Batch 2:  \n",
      "Loss = 0.06861665099859238 \t Accuracy = 0.6667999029159546\n",
      "\n",
      "Epoch 42, CIFAR-10 Batch 3:  \n",
      "Loss = 0.04294664040207863 \t Accuracy = 0.682999849319458\n",
      "\n",
      "Epoch 42, CIFAR-10 Batch 4:  \n",
      "Loss = 0.06969820708036423 \t Accuracy = 0.6767998933792114\n",
      "\n",
      "Epoch 42, CIFAR-10 Batch 5:  \n",
      "Loss = 0.08974975347518921 \t Accuracy = 0.6795998811721802\n",
      "\n",
      "Epoch 43, CIFAR-10 Batch 1:  \n",
      "Loss = 0.12504969537258148 \t Accuracy = 0.6863998770713806\n",
      "\n",
      "Epoch 43, CIFAR-10 Batch 2:  \n",
      "Loss = 0.05716310441493988 \t Accuracy = 0.671599805355072\n",
      "\n",
      "Epoch 43, CIFAR-10 Batch 3:  \n",
      "Loss = 0.04097353294491768 \t Accuracy = 0.6635999083518982\n",
      "\n",
      "Epoch 43, CIFAR-10 Batch 4:  \n",
      "Loss = 0.06276725232601166 \t Accuracy = 0.6755998134613037\n",
      "\n",
      "Epoch 43, CIFAR-10 Batch 5:  \n",
      "Loss = 0.09089571237564087 \t Accuracy = 0.6885998845100403\n",
      "\n",
      "Epoch 44, CIFAR-10 Batch 1:  \n",
      "Loss = 0.12285353988409042 \t Accuracy = 0.6751998662948608\n",
      "\n",
      "Epoch 44, CIFAR-10 Batch 2:  \n",
      "Loss = 0.06954991817474365 \t Accuracy = 0.6675998568534851\n",
      "\n",
      "Epoch 44, CIFAR-10 Batch 3:  \n",
      "Loss = 0.038612257689237595 \t Accuracy = 0.6649999022483826\n",
      "\n",
      "Epoch 44, CIFAR-10 Batch 4:  \n",
      "Loss = 0.05368460714817047 \t Accuracy = 0.682999849319458\n",
      "\n",
      "Epoch 44, CIFAR-10 Batch 5:  \n",
      "Loss = 0.0976555272936821 \t Accuracy = 0.6781998872756958\n",
      "\n",
      "Epoch 45, CIFAR-10 Batch 1:  \n",
      "Loss = 0.11852490901947021 \t Accuracy = 0.6837998628616333\n",
      "\n",
      "Epoch 45, CIFAR-10 Batch 2:  \n",
      "Loss = 0.055936068296432495 \t Accuracy = 0.678399920463562\n",
      "\n",
      "Epoch 45, CIFAR-10 Batch 3:  \n",
      "Loss = 0.03767773509025574 \t Accuracy = 0.6845998167991638\n",
      "\n",
      "Epoch 45, CIFAR-10 Batch 4:  \n",
      "Loss = 0.059234924614429474 \t Accuracy = 0.6755998730659485\n",
      "\n",
      "Epoch 45, CIFAR-10 Batch 5:  \n",
      "Loss = 0.08508826792240143 \t Accuracy = 0.6877998113632202\n",
      "\n",
      "Epoch 46, CIFAR-10 Batch 1:  \n",
      "Loss = 0.1271146684885025 \t Accuracy = 0.6773999333381653\n",
      "\n",
      "Epoch 46, CIFAR-10 Batch 2:  \n",
      "Loss = 0.04787157103419304 \t Accuracy = 0.6815998554229736\n",
      "\n",
      "Epoch 46, CIFAR-10 Batch 3:  \n",
      "Loss = 0.03896299749612808 \t Accuracy = 0.6787999272346497\n",
      "\n",
      "Epoch 46, CIFAR-10 Batch 4:  \n",
      "Loss = 0.05777015909552574 \t Accuracy = 0.6701998710632324\n",
      "\n",
      "Epoch 46, CIFAR-10 Batch 5:  \n",
      "Loss = 0.07385101914405823 \t Accuracy = 0.6863999366760254\n",
      "\n",
      "Epoch 47, CIFAR-10 Batch 1:  \n",
      "Loss = 0.13043558597564697 \t Accuracy = 0.6809998750686646\n",
      "\n",
      "Epoch 47, CIFAR-10 Batch 2:  \n",
      "Loss = 0.051092538982629776 \t Accuracy = 0.6633998155593872\n",
      "\n",
      "Epoch 47, CIFAR-10 Batch 3:  \n",
      "Loss = 0.023362847045063972 \t Accuracy = 0.6783998608589172\n",
      "\n",
      "Epoch 47, CIFAR-10 Batch 4:  \n",
      "Loss = 0.0534350723028183 \t Accuracy = 0.6799998879432678\n",
      "\n",
      "Epoch 47, CIFAR-10 Batch 5:  \n",
      "Loss = 0.055603571236133575 \t Accuracy = 0.6903998255729675\n",
      "\n",
      "Epoch 48, CIFAR-10 Batch 1:  \n",
      "Loss = 0.12628571689128876 \t Accuracy = 0.6843998432159424\n",
      "\n",
      "Epoch 48, CIFAR-10 Batch 2:  \n",
      "Loss = 0.0488760843873024 \t Accuracy = 0.6739999055862427\n",
      "\n",
      "Epoch 48, CIFAR-10 Batch 3:  \n",
      "Loss = 0.03531082347035408 \t Accuracy = 0.6851999163627625\n",
      "\n",
      "Epoch 48, CIFAR-10 Batch 4:  \n",
      "Loss = 0.05110441520810127 \t Accuracy = 0.6841999292373657\n",
      "\n",
      "Epoch 48, CIFAR-10 Batch 5:  \n",
      "Loss = 0.07243490219116211 \t Accuracy = 0.68479984998703\n",
      "\n",
      "Epoch 49, CIFAR-10 Batch 1:  \n",
      "Loss = 0.10622230917215347 \t Accuracy = 0.6831998229026794\n",
      "\n",
      "Epoch 49, CIFAR-10 Batch 2:  \n",
      "Loss = 0.05093434825539589 \t Accuracy = 0.6771998405456543\n",
      "\n",
      "Epoch 49, CIFAR-10 Batch 3:  \n",
      "Loss = 0.03271986544132233 \t Accuracy = 0.6787998676300049\n",
      "\n",
      "Epoch 49, CIFAR-10 Batch 4:  \n",
      "Loss = 0.048039454966783524 \t Accuracy = 0.679999828338623\n",
      "\n",
      "Epoch 49, CIFAR-10 Batch 5:  \n",
      "Loss = 0.0653509795665741 \t Accuracy = 0.6955997943878174\n",
      "\n",
      "Epoch 50, CIFAR-10 Batch 1:  \n",
      "Loss = 0.10378983616828918 \t Accuracy = 0.6797999143600464\n",
      "\n",
      "Epoch 50, CIFAR-10 Batch 2:  \n",
      "Loss = 0.05524522066116333 \t Accuracy = 0.6759998798370361\n",
      "\n",
      "Epoch 50, CIFAR-10 Batch 3:  \n",
      "Loss = 0.03728051856160164 \t Accuracy = 0.6763999462127686\n",
      "\n",
      "Epoch 50, CIFAR-10 Batch 4:  \n",
      "Loss = 0.047182224690914154 \t Accuracy = 0.6867998838424683\n",
      "\n",
      "Epoch 50, CIFAR-10 Batch 5:  \n",
      "Loss = 0.07981189340353012 \t Accuracy = 0.6843998432159424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.68212890625\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w+IsAryE7vTVgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bf1e0c7668>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
